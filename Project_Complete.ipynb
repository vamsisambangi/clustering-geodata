{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Project_Complete.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZRIJGuFsLkRd"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vamsisambangi/clustering-geolocation-data/blob/master/Project_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-26T15:10:30.523891Z",
          "start_time": "2019-08-26T15:10:30.512093Z"
        },
        "id": "b95mt9ITLkON",
        "colab_type": "text"
      },
      "source": [
        "# Clustering Geolocation Data Intelligently in Python\n",
        "We have taxi rank locations, and want to define key clusters of these taxis where we can build service stations for all taxis operating in that region.\n",
        "\n",
        "## Prerequisites\n",
        "- Basic Matplotlib skills for plotting 2-D data clearly.\n",
        "- Basic understanding of Pandas and how to use it for data manipulation.\n",
        "- The concepts behind clustering algorithms, although we will go through this throughout the project.\n",
        "\n",
        "## Project Outline\n",
        "\n",
        "[**Task 1**](#task1): Exploratory Data Analysis\n",
        "\n",
        "[**Task 2**](#task2): Visualizing Geographical Data\n",
        "\n",
        "[**Task 3**](#task3): Clustering Strength / Performance Metric\n",
        "\n",
        "[**Task 4**](#task4): K-Means Clustering\n",
        "\n",
        "[**Task 5**](#task5): DBSCAN\n",
        "\n",
        "[**Task 6**](#task6): HDBSCAN\n",
        "\n",
        "[**Task 7**](#task7): Addressing Outliers\n",
        "\n",
        "[**Further Reading**](#further)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IsXxS3fMi4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to upgrade numpy for hdbscan\n",
        "!pip install numpy==1.16.0\n",
        "\n",
        "# install this first before hdbscan\n",
        "!pip install Cython\n",
        "\n",
        "!pip install hdbscan\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnSvsPH0LkOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from ipywidgets import interactive\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import hdbscan\n",
        "import folium\n",
        "import re\n",
        "\n",
        "\n",
        "cols = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4',\n",
        "        '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', \n",
        "        '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', \n",
        "        '#000075', '#808080']*10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PZXCBNsLkOT",
        "colab_type": "text"
      },
      "source": [
        "<a id='task1'></a>\n",
        "# Task 1: Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-26T15:10:31.177864Z",
          "start_time": "2019-08-26T15:10:31.164667Z"
        },
        "id": "Faq6BVVYLkOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('taxi_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-26T15:10:31.688300Z",
          "start_time": "2019-08-26T15:10:31.673561Z"
        },
        "id": "RF5H9Op6LkOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cMLBmBiLkOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.duplicated(subset=['LON', 'LAT']).values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQD5crXHLkOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isna().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzZUTaONLkOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Before dropping NaNs and dupes\\t:\\tdf.shape = {df.shape}')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(subset=['LON', 'LAT'], keep='first', inplace=True)\n",
        "print(f'After dropping NaNs and dupes\\t:\\tdf.shape = {df.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNIYe0xWLkOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E12_9KSSLkOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df[['LON', 'LAT']], dtype='float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ2LSf6wLkO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:,0], X[:,1], alpha=0.2, s=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU_tQKChLkPE",
        "colab_type": "text"
      },
      "source": [
        "<a id='task2'></a>\n",
        "# Task 2: Visualizing Geographical Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo-SA9FrLkPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = folium.Map(location=[df.LAT.mean(), df.LON.mean()], zoom_start=9, \n",
        "               tiles='Stamen Toner')\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row.LAT, row.LON],\n",
        "        radius=5,\n",
        "        popup=re.sub(r'[^a-zA-Z ]+', '', row.NAME),\n",
        "        color='#1787FE',\n",
        "        fill=True,\n",
        "        fill_colour='#1787FE'\n",
        "    ).add_to(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-08-26T15:10:34.638124Z",
          "start_time": "2019-08-26T15:10:34.635069Z"
        },
        "id": "cTzUesAtLkPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN6eXNBqLkPL",
        "colab_type": "text"
      },
      "source": [
        "<a id='task3'></a>\n",
        "# Task 3: Clustering Strength / Performance Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkgFupSJLkPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_blobs, _ = make_blobs(n_samples=1000, centers=10, n_features=2, \n",
        "                        cluster_std=0.5, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4TvPsMALkPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X_blobs[:,0], X_blobs[:,1], alpha=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2HkIRmfLkPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_predictions = np.load('sample_clusters.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msy5p5QNLkPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_clusters = np.unique(class_predictions)\n",
        "for unique_cluster in unique_clusters:\n",
        "    X = X_blobs[class_predictions==unique_cluster]\n",
        "    plt.scatter(X[:,0], X[:,1], alpha=0.2, c=cols[unique_cluster])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCKocrw-LkPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "silhouette_score(X_blobs, class_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6tY326wLkPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_predictions = np.load('sample_clusters_improved.npy')\n",
        "unique_clusters = np.unique(class_predictions)\n",
        "for unique_cluster in unique_clusters:\n",
        "    X = X_blobs[class_predictions==unique_cluster]\n",
        "    plt.scatter(X[:,0], X[:,1], alpha=0.2, c=cols[unique_cluster])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg3pFv4SLkPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "silhouette_score(X_blobs, class_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHhzbzqALkPi",
        "colab_type": "text"
      },
      "source": [
        "<a id='task4'></a>\n",
        "# Task 4: K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoJLt17GLkPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_blobs, _ = make_blobs(n_samples=1000, centers=50, \n",
        "                        n_features=2, cluster_std=1, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5LBXIBYLkP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = defaultdict(dict)\n",
        "for x in range(1,21):\n",
        "    model = KMeans(n_clusters=3, random_state=17, \n",
        "                   max_iter=x, n_init=1).fit(X_blobs)\n",
        "    \n",
        "    data[x]['class_predictions'] = model.predict(X_blobs)\n",
        "    data[x]['centroids'] = model.cluster_centers_\n",
        "    data[x]['unique_classes'] = np.unique(class_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dRukAAlLkP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "    class_predictions = data[x]['class_predictions']\n",
        "    centroids = data[x]['centroids']\n",
        "    unique_classes = data[x]['unique_classes']\n",
        "\n",
        "    for unique_class in unique_classes:\n",
        "            plt.scatter(X_blobs[class_predictions==unique_class][:,0], \n",
        "                        X_blobs[class_predictions==unique_class][:,1], \n",
        "                        alpha=0.3, c=cols[unique_class])\n",
        "    plt.scatter(centroids[:,0], centroids[:,1], s=200, c='#000000', marker='v')\n",
        "    plt.ylim([-15,15]); plt.xlim([-15,15])\n",
        "    plt.title('How K-Means Clusters')\n",
        "\n",
        "interactive_plot = interactive(f, x=(1, 20))\n",
        "output = interactive_plot.children[-1]\n",
        "output.layout.height = '350px'\n",
        "interactive_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6CKeHq6LkP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df[['LON', 'LAT']], dtype='float64')\n",
        "k = 70\n",
        "model = KMeans(n_clusters=k, random_state=17).fit(X)\n",
        "class_predictions = model.predict(X)\n",
        "df[f'CLUSTER_kmeans{k}'] = class_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znWR8UKbLkQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR4Z8S4uLkQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_map(df, cluster_column):\n",
        "    m = folium.Map(location=[df.LAT.mean(), df.LON.mean()], zoom_start=9, tiles='Stamen Toner')\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "\n",
        "        if row[cluster_column] == -1:\n",
        "            cluster_colour = '#000000'\n",
        "        else:\n",
        "            cluster_colour = cols[row[cluster_column]]\n",
        "\n",
        "        folium.CircleMarker(\n",
        "            location= [row['LAT'], row['LON']],\n",
        "            radius=5,\n",
        "            popup=str(row[cluster_column]),\n",
        "            color=cluster_colour,\n",
        "            fill=True,\n",
        "            fill_color=cluster_colour\n",
        "        ).add_to(m)\n",
        "        \n",
        "    return m\n",
        "\n",
        "m = create_map(df, 'CLUSTER_kmeans70')\n",
        "print(f'K={k}')\n",
        "print(f'Silhouette Score: {silhouette_score(X, class_predictions)}')\n",
        "\n",
        "m.save('kmeans_70.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNkVOEgLkQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkswe02nLkQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_silhouette, best_k = -1, 0\n",
        "\n",
        "for k in tqdm(range(2, 100)):\n",
        "    model = KMeans(n_clusters=k, random_state=1).fit(X)\n",
        "    class_predictions = model.predict(X)\n",
        "    \n",
        "    curr_silhouette = silhouette_score(X, class_predictions)\n",
        "    if curr_silhouette > best_silhouette:\n",
        "        best_k = k\n",
        "        best_silhouette = curr_silhouette\n",
        "        \n",
        "print(f'K={best_k}')\n",
        "print(f'Silhouette Score: {best_silhouette}') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOgNihFOLkQb",
        "colab_type": "text"
      },
      "source": [
        "<a id='task5'></a>\n",
        "# Task 5: DBSCAN \n",
        "Density-Based Spatial Clustering of Applications with Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWKSNQJSLkQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for indexing out certain values\n",
        "dummy = np.array([-1, -1, -1, 2, 3, 4, 5, -1])\n",
        "\n",
        "new = np.array([(counter+2)*x if x==-1 else x for counter, x in enumerate(dummy)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nxaFrIxLkQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DBSCAN(eps=0.01, min_samples=5).fit(X)\n",
        "class_predictions = model.labels_\n",
        "\n",
        "df['CLUSTERS_DBSCAN'] = class_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifRW2bjJLkQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = create_map(df, 'CLUSTERS_DBSCAN')\n",
        "\n",
        "    \n",
        "print(f'Number of clusters found: {len(np.unique(class_predictions))}')\n",
        "print(f'Number of outliers found: {len(class_predictions[class_predictions==-1])}')\n",
        "\n",
        "print(f'Silhouette ignoring outliers: {silhouette_score(X[class_predictions!=-1], class_predictions[class_predictions!=-1])}')\n",
        "\n",
        "no_outliers = 0\n",
        "no_outliers = np.array([(counter+2)*x if x==-1 else x for counter, x in enumerate(class_predictions)])\n",
        "print(f'Silhouette outliers as singletons: {silhouette_score(X, no_outliers)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo_ZHq2RLkQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML0Pb8RzLkQu",
        "colab_type": "text"
      },
      "source": [
        "<a id='task6'></a>\n",
        "# Task 6: HDBSCAN\n",
        "Hierarchical DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBIzHBrrLkQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=2, \n",
        "                        cluster_selection_epsilon=0.01)\n",
        "#min_cluster_size\n",
        "#min_samples\n",
        "#cluster_slection_epsilon\n",
        "\n",
        "class_predictions = model.fit_predict(X)\n",
        "df['CLUSTER_HDBSCAN'] = class_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiuGjlDlLkQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = create_map(df, 'CLUSTER_HDBSCAN')\n",
        "\n",
        "print(f'Number of clusters found: {len(np.unique(class_predictions))-1}')\n",
        "print(f'Number of outliers found: {len(class_predictions[class_predictions==-1])}')\n",
        "\n",
        "print(f'Silhouette ignoring outliers: {silhouette_score(X[class_predictions!=-1], class_predictions[class_predictions!=-1])}')\n",
        "\n",
        "no_outliers = np.array([(counter+2)*x if x==-1 else x for counter, x in enumerate(class_predictions)])\n",
        "print(f'Silhouette outliers as singletons: {silhouette_score(X, no_outliers)}')\n",
        "\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZYr5kULLkQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hdbscan.HDBSCAN?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOdM7EoxLkQ6",
        "colab_type": "text"
      },
      "source": [
        "<a id='task7'></a>\n",
        "# Task 7: Addressing Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6nKfdfeLkQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb8fFWtnLkQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df[df.CLUSTER_HDBSCAN!=-1]\n",
        "df_predict = df[df.CLUSTER_HDBSCAN==-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPDMLi3LkRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(df_train[['LON', 'LAT']], dtype='float64')\n",
        "y_train = np.array(df_train['CLUSTER_HDBSCAN'])\n",
        "\n",
        "X_predict = np.array(df_predict[['LON', 'LAT']], dtype='float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1X5wPchLkRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avPsb8u9LkRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = classifier.predict(X_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBFv2lc9LkRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['CLUSTER_hybrid'] = df['CLUSTER_HDBSCAN']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3GRNZVLLkRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[df.CLUSTER_HDBSCAN==-1, 'CLUSTER_hybrid'] = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9mOOZqMLkRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = create_map(df, 'CLUSTER_hybrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Ayx2BxLkRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGXVVnKXLkRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_predictions = df.CLUSTER_hybrid\n",
        "print(f'Number of clusters found: {len(np.unique(class_predictions))}')\n",
        "print(f'Silhouette: {silhouette_score(X, class_predictions)}')\n",
        "\n",
        "m.save('hybrid.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue2Gvy2WLkRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['CLUSTER_hybrid'].value_counts().plot.hist(bins=70, alpha=0.4, \n",
        "                                              label='Hybrid')\n",
        "df['CLUSTER_kmeans70'].value_counts().plot.hist(bins=70, alpha=0.4,\n",
        "                                               label='K-Means (70)')\n",
        "plt.legend()\n",
        "plt.title('Comparing Hybrid and K-Means Approaches')\n",
        "plt.xlabel('Cluster Sizes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcNeBIgfLkRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRIJGuFsLkRd",
        "colab_type": "text"
      },
      "source": [
        "<a id='further'></a>\n",
        "# Further Reading\n",
        "\n",
        "For some additional reading, feel free to check out [K-Means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html), and [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/) clustering respectively.\n",
        "\n",
        "It may be of use to also check out [other forms of clustering](https://scikit-learn.org/stable/modules/clustering.html) that are commonly used and available in the scikit-learn library. HDBSCAN documentation also includes [a good methodology](https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html) for choosing your clustering algorithm based on your dataset and other limiting factors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7v8ONHJLkRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}